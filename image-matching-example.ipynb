{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 4 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m timg1 \u001b[39m=\u001b[39m kornia\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mimage_to_tensor(np\u001b[39m.\u001b[39marray(img1), \u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n\u001b[1;32m     23\u001b[0m timg2 \u001b[39m=\u001b[39m kornia\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mimage_to_tensor(np\u001b[39m.\u001b[39marray(img2), \u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m \u001b[39m255.\u001b[39m\n\u001b[0;32m---> 25\u001b[0m timg \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([timg1,timg2], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m timg_gray \u001b[39m=\u001b[39m kornia\u001b[39m.\u001b[39mcolor\u001b[39m.\u001b[39mrgb_to_grayscale(timg)\n\u001b[1;32m     29\u001b[0m plt\u001b[39m.\u001b[39mimshow(kornia\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mtensor_to_image(timg[\u001b[39m0\u001b[39m]))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 4 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "#First load libraries and images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import kornia\n",
    "import cv2\n",
    "from kornia.feature import *\n",
    "from time import time\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "from kornia.color import rgb_to_grayscale\n",
    "\n",
    "# img1 = Image.open('data/matching/graffiti.png')\n",
    "# img2 = Image.open('data/matching/graffiti4.ppm')#.resize(img1.size)\n",
    "img1 = Image.open('input_photos/temp1.png')\n",
    "img2 = Image.open('input_photos/temp3.ppm')\n",
    "\n",
    "timg1 = kornia.utils.image_to_tensor(np.array(img1), False).float() / 255.\n",
    "timg2 = kornia.utils.image_to_tensor(np.array(img2), False).float() / 255.\n",
    "\n",
    "timg = torch.cat([timg1,timg2], dim=0)\n",
    "\n",
    "timg_gray = kornia.color.rgb_to_grayscale(timg)\n",
    "\n",
    "plt.imshow(kornia.utils.tensor_to_image(timg[0]))\n",
    "plt.figure()\n",
    "plt.imshow(kornia.utils.tensor_to_image(timg[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define some functions for local feature matching\n",
    "\n",
    "def visualize_LAF(img, LAF, img_idx = 0):\n",
    "    x, y = kornia.feature.laf.get_laf_pts_to_draw(LAF, img_idx)\n",
    "    plt.figure()\n",
    "    plt.imshow(kornia.utils.tensor_to_image(img[img_idx]))\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets define local deature detector and descriptor\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobHessian()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(19),\n",
    "                              mr_size=6.0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now lets define  affine local deature detector and descriptor\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobHessian()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(19),\n",
    "                              aff_module=kornia.feature.LAFAffineShapeEstimator(19),\n",
    "                              mr_size=6.0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now lets define  affine local deature detector and descriptor\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobHessian()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(19),\n",
    "                              aff_module=kornia.feature.LAFAffineShapeEstimator(19),\n",
    "                              #kornia.feature.LAFAffNetShapeEstimator(True),\n",
    "                              mr_size=6.0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now lets define  affine local deature detector and descriptor\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobHessian()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(19),\n",
    "                              aff_module=kornia.feature.LAFAffNetShapeEstimator(True),\n",
    "                              mr_size=6.0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try with Difference-of-Gaussians, aka SIFT keypoints\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobDoG()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              scale_space_response=True,#We need that, because DoG operates on scale-space\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(19),\n",
    "                              mr_size=6.0,\n",
    "                              minima_are_also_good=True).to(device) #dark blobs are as good as bright.\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets try with Difference-of-Gaussians + OriNet + TFeat\n",
    "\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')\n",
    "\n",
    "PS = 41\n",
    "\n",
    "sift = kornia.feature.TFeat(True).to(device)\n",
    "sift = kornia.feature.SIFTDescriptor(PS, rootsift=True).to(device)\n",
    "\n",
    "descriptor = sift\n",
    "\n",
    "resp = BlobDoG()\n",
    "scale_pyr = kornia.geometry.ScalePyramid(3, 1.6, PS, double_image=True)\n",
    "\n",
    "nms = kornia.geometry.ConvQuadInterp3d(10)\n",
    "\n",
    "n_features = 4000\n",
    "detector = ScaleSpaceDetector(n_features,\n",
    "                              resp_module=resp,\n",
    "                              scale_space_response=True,#We need that, because DoG operates on scale-space\n",
    "                              nms_module=nms,\n",
    "                              scale_pyr_module=scale_pyr,\n",
    "                              ori_module=kornia.feature.LAFOrienter(32, \n",
    "                                                                    angle_detector=kornia.feature.OriNet(True)),\n",
    "                              mr_size=6.0,\n",
    "                              minima_are_also_good=True).to(device) #dark blobs are as good as bright.\n",
    "\n",
    "with torch.no_grad():\n",
    "    lafs, resps = detector(timg_gray)\n",
    "    patches =  kornia.feature.extract_patches_from_pyramid(timg_gray, lafs, PS)\n",
    "    B, N, CH, H, W = patches.size()\n",
    "    # Descriptor accepts standard tensor [B, CH, H, W], while patches are [B, N, CH, H, W] shape\n",
    "    # So we need to reshape a bit :) \n",
    "    descs = descriptor(patches.view(B * N, CH, H, W)).view(B, N, -1)\n",
    "    scores, matches = kornia.feature.match_snn(descs[0], descs[1], 0.9)\n",
    "\n",
    "# Now RANSAC\n",
    "src_pts = lafs[0,matches[:,0], :, 2].data.cpu().numpy()\n",
    "dst_pts = lafs[1,matches[:,1], :, 2].data.cpu().numpy()\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1.0, 0.999, 10000)\n",
    "\n",
    "inliers = matches[torch.from_numpy(mask).bool().squeeze(), :]\n",
    "\n",
    "for i in range(2):\n",
    "    visualize_LAF(timg_gray, lafs[:,inliers[:,i]], i)\n",
    "print (len(inliers), 'inliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
